{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ST445_week5_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivianaWang/Repository-Test/blob/VivianaWang-patch-1/ST445_week5_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaY-AY53gf88"
      },
      "source": [
        "# ST445 Managing and Visualizing Data\n",
        "# More on web scraping and API\n",
        "\n",
        "### Week 5 lab, MT 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5OjQxgfhdlc"
      },
      "source": [
        "# Before class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN-_r7vMg4hC"
      },
      "source": [
        "1. Week5 class attendance register (See Zoom chat for the link): \n",
        "\n",
        "    https://forms.office.com/Pages/ResponsePage.aspx?id=_epnVXfnpUKRu5RA_UO4k9IU9K3OWZRDnfHYZ0uayQlUMTFaRUtKTFJKV0NGUENPNk9ETEY2RTdEVC4u\n",
        "\n",
        "2. A pull about if you have any questions regarding the week5's lecture material:\n",
        "https://forms.gle/8kj8fauMdMfFNKZT8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-5voq4AKkFj"
      },
      "source": [
        "# Plan for today\n",
        "\n",
        "- More about web scraping (unicode and regular expression)\n",
        "- Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeCf5zxkLErt"
      },
      "source": [
        "## Example: Web scraping the COPSS Awards Recipients\n",
        "\n",
        "Get information regarding statisticians that were awarded with the COPSS Presidents' Award. Get a dataframe with 3 columns (`Year`, `Name`, `Institute`). For example (`1981`, `Peter J. Bickel`, `University of California, Berkeley`). Set `Year` to be the index, `Name` and `Institute` as column names.\n",
        "\n",
        "https://en.wikipedia.org/wiki/COPSS_Presidents%27_Award\n",
        "\n",
        "Step 1: Go to the website, use Google Chrome > More Tools > Developer Tools to inspect the HTML code. We well find all those informtion in `<li>...</li>`\n",
        "\n",
        "Step 2: Find all these tags using `BeautifulSoup`. We want to select a subset of them.\n",
        "\n",
        "Step 3: Use the `.split` function to separate the year, name and institute. Specify an optional argument k in `.split` to split only on the k-th occurrence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dea6pI5gIah"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup  \n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fk91AtpgthS"
      },
      "source": [
        "url='https://en.wikipedia.org/wiki/COPSS_Presidents%27_Award'\n",
        "page=requests.get(url)\n",
        "soup=BeautifulSoup(page.content,'lxml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uc9X4cg78V9"
      },
      "source": [
        "lists = soup.find_all('li')\n",
        "records = []\n",
        "# print(lists)\n",
        "for li in lists:\n",
        "    # print(li.text)\n",
        "    char_element = li.text.split(': ')\n",
        "    if(len(char_element) == 2):\n",
        "        # print(char_element)\n",
        "        char = char_element[1].split(', ', 1)\n",
        "        # print([char,len(char)])\n",
        "        if(len(char) > 1):\n",
        "            records.append([char_element[0],char[0],char[1]])\n",
        "records\n",
        "copss_recipients = pd.DataFrame(records, columns =['Year', 'Name', 'Institute'])\n",
        "copss_recipients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GChhwVdmWs2O"
      },
      "source": [
        "## For each of these statisticians, find their year of birth. Create another column in your dataframe showing those information.\n",
        "\n",
        "Step 1: Go to the website https://en.wikipedia.org/wiki/Peter_J._Bickel, use Google Chrome > More Tools > Developer Tools to inspect the HTML code.\n",
        "\n",
        "Step 2: Find the tag containing the birth of year informtion and get the information using `BeautifulSoup`. We can use `soup.find(text='Born')` and `.findNext('td')`. To get birth of year from a give string, we can split it into two parts by 19 and get the first two characters in the second element. \n",
        "\n",
        "Step 3: To repeat this procedure for each of those statisticians in your dataframe, try something like this `'https://en.wikipedia.org/wiki/' + name`. It does not contain year of birth for all statisticians. If there are no such information for a particular statistician, you can set its value to be `NA`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQd3ZsWk8qwu",
        "outputId": "376a2f57-7fe4-46c6-bb50-7bf8f9cd06d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Birth = []\n",
        "for name in copss_recipients['Name']:\n",
        "    url = 'https://en.wikipedia.org/wiki/' + name.replace(' ', '_')\n",
        "    # print(url)\n",
        "    page=requests.get(url)\n",
        "    soup=BeautifulSoup(page.content,'lxml')\n",
        "    if(soup.find(text='Born') is not None):\n",
        "        tmp = soup.find(text='Born').findNext('td').text.split('19')\n",
        "        Birth.append('19' + tmp[1][:2])\n",
        "    else:\n",
        "        tmp = soup.find_all('p')[0].text\n",
        "        tmp1 = re.search(r'born\\s(\\d{4})',tmp)\n",
        "        if(tmp1 is not None):\n",
        "            Birth.append(tmp1.group(1))\n",
        "        else:\n",
        "            Birth.append('NA')\n",
        "\n",
        "copss_recipients['Birth year'] = Birth\n",
        "copss_recipients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "      <th>Institute</th>\n",
              "      <th>Birth year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981</td>\n",
              "      <td>Peter J. Bickel</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>1940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1982</td>\n",
              "      <td>Stephen Fienberg</td>\n",
              "      <td>Carnegie Mellon University</td>\n",
              "      <td>1942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1983</td>\n",
              "      <td>Tze Leung Lai</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>1945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1984</td>\n",
              "      <td>David V. Hinkley</td>\n",
              "      <td>University of California, Santa Barbara</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1985</td>\n",
              "      <td>James O. Berger</td>\n",
              "      <td>Duke University</td>\n",
              "      <td>1950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1986</td>\n",
              "      <td>Ross L. Prentice</td>\n",
              "      <td>Fred Hutchinson Cancer Research Center</td>\n",
              "      <td>1946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1987</td>\n",
              "      <td>C.F. Jeff Wu</td>\n",
              "      <td>Georgia Institute of Technology</td>\n",
              "      <td>1949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1988</td>\n",
              "      <td>Raymond J. Carroll</td>\n",
              "      <td>Texas A&amp;M University</td>\n",
              "      <td>1949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1989</td>\n",
              "      <td>Peter Hall</td>\n",
              "      <td>Australian National University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1990</td>\n",
              "      <td>Peter McCullagh</td>\n",
              "      <td>University of Chicago</td>\n",
              "      <td>1952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1991</td>\n",
              "      <td>Bernard Silverman</td>\n",
              "      <td>University of Oxford</td>\n",
              "      <td>1952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1992</td>\n",
              "      <td>Nancy Reid</td>\n",
              "      <td>University of Toronto</td>\n",
              "      <td>1952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1993</td>\n",
              "      <td>Wing Hung Wong</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1994</td>\n",
              "      <td>David L. Donoho</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>1957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1995</td>\n",
              "      <td>Iain M. Johnstone</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>1956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1996</td>\n",
              "      <td>Robert J. Tibshirani</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>1956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1997</td>\n",
              "      <td>Kathryn Roeder</td>\n",
              "      <td>Carnegie Mellon University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1998</td>\n",
              "      <td>Pascal Massart</td>\n",
              "      <td>Université de Paris-Sud</td>\n",
              "      <td>1958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1999</td>\n",
              "      <td>Larry A. Wasserman</td>\n",
              "      <td>Carnegie Mellon University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2000</td>\n",
              "      <td>Jianqing Fan</td>\n",
              "      <td>Princeton University</td>\n",
              "      <td>1962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2001</td>\n",
              "      <td>Xiao-Li Meng</td>\n",
              "      <td>Harvard University</td>\n",
              "      <td>1963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2002</td>\n",
              "      <td>Jun Liu</td>\n",
              "      <td>Harvard University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2003</td>\n",
              "      <td>Andrew Gelman</td>\n",
              "      <td>Columbia University</td>\n",
              "      <td>1965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2004</td>\n",
              "      <td>Michael A. Newton</td>\n",
              "      <td>University of Wisconsin</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2005</td>\n",
              "      <td>Mark J. van der Laan</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2006</td>\n",
              "      <td>Xihong Lin</td>\n",
              "      <td>Harvard University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2007</td>\n",
              "      <td>Jeff Rosenthal</td>\n",
              "      <td>University of Toronto</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2008</td>\n",
              "      <td>T. Tony Cai</td>\n",
              "      <td>University of Pennsylvania</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2009</td>\n",
              "      <td>Rafael Irizarry</td>\n",
              "      <td>Harvard University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2010</td>\n",
              "      <td>David Dunson</td>\n",
              "      <td>Duke University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2011</td>\n",
              "      <td>Nilanjan Chatterjee</td>\n",
              "      <td>Johns Hopkins University</td>\n",
              "      <td>1972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2012</td>\n",
              "      <td>Samuel Kou</td>\n",
              "      <td>Harvard University</td>\n",
              "      <td>1974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2013</td>\n",
              "      <td>Marc A. Suchard</td>\n",
              "      <td>UCLA</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2014</td>\n",
              "      <td>Martin J. Wainwright</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2015</td>\n",
              "      <td>John D. Storey</td>\n",
              "      <td>Princeton University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2016</td>\n",
              "      <td>Nicolai Meinshausen</td>\n",
              "      <td>ETH Zürich</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2017</td>\n",
              "      <td>Tyler J. VanderWeele</td>\n",
              "      <td>Harvard University</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2018</td>\n",
              "      <td>Richard J. Samworth</td>\n",
              "      <td>University of Cambridge</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2019</td>\n",
              "      <td>Hadley Wickham</td>\n",
              "      <td>RStudio, Inc.</td>\n",
              "      <td>1979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2020</td>\n",
              "      <td>Rina Foygel Barber</td>\n",
              "      <td>University of Chicago</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Year  ... Birth year\n",
              "0   1981  ...       1940\n",
              "1   1982  ...       1942\n",
              "2   1983  ...       1945\n",
              "3   1984  ...         NA\n",
              "4   1985  ...       1950\n",
              "5   1986  ...       1946\n",
              "6   1987  ...       1949\n",
              "7   1988  ...       1949\n",
              "8   1989  ...         NA\n",
              "9   1990  ...       1952\n",
              "10  1991  ...       1952\n",
              "11  1992  ...       1952\n",
              "12  1993  ...         NA\n",
              "13  1994  ...       1957\n",
              "14  1995  ...       1956\n",
              "15  1996  ...       1956\n",
              "16  1997  ...         NA\n",
              "17  1998  ...       1958\n",
              "18  1999  ...         NA\n",
              "19  2000  ...       1962\n",
              "20  2001  ...       1963\n",
              "21  2002  ...         NA\n",
              "22  2003  ...       1965\n",
              "23  2004  ...         NA\n",
              "24  2005  ...       1967\n",
              "25  2006  ...         NA\n",
              "26  2007  ...       1967\n",
              "27  2008  ...         NA\n",
              "28  2009  ...         NA\n",
              "29  2010  ...         NA\n",
              "30  2011  ...       1972\n",
              "31  2012  ...       1974\n",
              "32  2013  ...         NA\n",
              "33  2014  ...         NA\n",
              "34  2015  ...         NA\n",
              "35  2016  ...         NA\n",
              "36  2017  ...         NA\n",
              "37  2018  ...         NA\n",
              "38  2019  ...       1979\n",
              "39  2020  ...         NA\n",
              "\n",
              "[40 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpotc9IVgGgm",
        "outputId": "74f9a455-1471-49bf-ce88-c13185ece0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "url = 'https://en.wikipedia.org/wiki/C._F._Jeff_Wu'\n",
        "page=requests.get(url)\n",
        "soup=BeautifulSoup(page.content,'lxml')\n",
        "tmp = re.search(r'born\\s(\\d{4})',soup.find_all('p')[0].text)\n",
        "tmp.group(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1949'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4IthprlLsJU"
      },
      "source": [
        "## Regular expression in python\n",
        "- Wiki: https://en.wikipedia.org/wiki/Regular_expression\n",
        "- Cheetsheet: https://www.debuggex.com/cheatsheet/regex/python\n",
        "- Tutorial: https://developers.google.com/edu/python/regular-expressions, https://github.com/ziishaned/learn-regex\n",
        "- Online practising https://regex101.com/\n",
        "\n",
        "## Several examples\n",
        "- Date format: YYYY-MM-DD r\"\\d{4}-\\d{2}-\\d{2}\"\n",
        "- text: My phone number is 421-2343-121, \n",
        "    - word with 6 characters r'\\b\\w{6}\\b'\n",
        "    - parse phone number (\\d{3})-(\\d{4})-(\\d{3})\n",
        "\n",
        "- test the strength of password"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4jVV7qZgJLr",
        "outputId": "c27b68c9-dbc6-4bb4-cd52-92c137226001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = '1981: Peter J. Bickel, University of California, Berkeley'\n",
        "tmp = re.search(r'(\\d{4}):\\s+([^,]*),\\s+(\\w.*)', text)\n",
        "tmp.group(1,2,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1981', 'Peter J. Bickel', 'University of California, Berkeley')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxKVbabjfw2J"
      },
      "source": [
        "## solution using regular expression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRZwpZwdfPKn"
      },
      "source": [
        "lists = soup.find_all('li')\n",
        "records = []\n",
        "for li in lists:\n",
        "    substr = re.search(r'(\\d{4}):\\s+([^,]*),\\s+(\\w.*)',li.text)\n",
        "    if(substr is not None):\n",
        "        records.append(substr.group(1,2,3))\n",
        "copss_recipients = pd.DataFrame(records, columns =['Year', 'Name', 'Institute'])\n",
        "copss_recipients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5FH6JSRXTEL"
      },
      "source": [
        "### Unicode \n",
        "A coding system that map every characters (letter from almost all languages, number, special characters, etc). \n",
        "\n",
        "- As of March 2020, it contains 143,859 characters\n",
        "- In contrast, ASCII only contains 128 specified characters.\n",
        "- Unicode standard:  UTF-8, UTF-16, etc\n",
        "- wiki: https://en.wikipedia.org/wiki/Unicode\n",
        "- https://unicode-table.com/en/\n",
        "- En dash: '–' with unicode \\u2013 in python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyP1FT1CabUq"
      },
      "source": [
        "# Exercise: Web Scraping the Characters in the ``Three-Body\" Novel Series From"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgCxrnWxb4Et"
      },
      "source": [
        "## One implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFhtEGJfCq8N",
        "outputId": "b1e28b13-a597-4145-8233-3f268bb129a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "urls = ['https://en.wikipedia.org/wiki/The_Three-Body_Problem_(novel)',\n",
        "        'https://en.wikipedia.org/wiki/The_Dark_Forest',\n",
        "        'https://en.wikipedia.org/wiki/Death%27s_End']\n",
        "characters = []\n",
        "for i, url in enumerate(urls):\n",
        "    page=requests.get(url)\n",
        "    soup=BeautifulSoup(page.content,'lxml')\n",
        "    lists = soup.find_all('li')\n",
        "    for li in lists:\n",
        "        element = re.split(' \\u2013 ', li.text)\n",
        "        if(len(element) < 2):\n",
        "            continue\n",
        "        characters.append([element[0], i])\n",
        "characters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Ye Zhetai (叶哲泰)', 0],\n",
              " ['Shao Lin (绍琳)', 0],\n",
              " ['Ye Wenjie (叶文洁)', 0],\n",
              " ['Ye Wenxue (叶文雪)', 0],\n",
              " ['Lei Zhicheng (雷志成)', 0],\n",
              " ['Yang Weining (杨卫宁)', 0],\n",
              " ['Wang Miao (汪淼)', 0],\n",
              " ['Yang Dong (杨冬)', 0],\n",
              " ['Ding Yi (丁仪)', 0],\n",
              " ['Shi Qiang (史强)', 0],\n",
              " ['Chang Weisi (常伟思)', 0],\n",
              " ['Shen Yufei (申玉菲)', 0],\n",
              " ['Wei Cheng (魏成)', 0],\n",
              " ['Pan Han (潘寒)', 0],\n",
              " ['Sha Ruishan (沙瑞山)', 0],\n",
              " ['Mike Evans (麦克·伊文斯)', 0],\n",
              " ['Colonel Stanton (斯坦顿)', 0],\n",
              " ['Ye Wenjie (叶文洁)', 1],\n",
              " ['Mike Evans (麦克·伊文斯)', 1],\n",
              " ['Chang Weisi (常伟思)', 1],\n",
              " ['Zhang Beihai (章北海)', 1],\n",
              " ['Zhang Yuanchao (张援朝)', 1],\n",
              " ['Shi Qiang (史强), also nicknamed Da Shi (大史)', 1],\n",
              " ['Wu Yue (吴岳)', 1],\n",
              " ['Zhuang Yan (庄颜)', 1],\n",
              " ['Ding Yi (丁仪)', 1],\n",
              " ['Dongfang Yanxu (东方延绪)', 1],\n",
              " ['Kent (坎特)', 1],\n",
              " ['Frederick Tyler (弗雷德里克·泰勒)', 1],\n",
              " ['Manuel Rey Diaz (曼努尔·雷迪亚兹)', 1],\n",
              " ['Bill Hines (比尔·希恩斯)', 1],\n",
              " ['Luo Ji (罗辑)', 1],\n",
              " ['Cheng Xin (程心)', 2],\n",
              " ['Yun Tianming (云天明)', 2],\n",
              " ['Thomas Wade (托马斯·维德)', 2],\n",
              " ['Ai AA (艾AA)', 2],\n",
              " ['Luo Ji (罗辑)', 2],\n",
              " ['Guan Yifan (关一帆)', 2],\n",
              " ['Yang Dong (杨冬)', 2],\n",
              " [\"^ Liu, Cixin (20 September 2016). Death's End. Tor Books. ASIN\\xa00765377101\",\n",
              "  2],\n",
              " ['^ Liu, Cixin (20 September 2016). \"Death\\'s End\". Tor Books', 2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF1kGcXBb7D3"
      },
      "source": [
        "## solution using regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHkOxbVZNQ8G",
        "outputId": "9d3eb4ee-52d8-426d-8ef8-e050e3abf0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# https://unicode-table.com/en/\n",
        "text = 'Cheng Xin (程心) – Aerospace engineer from the early 21st century, second Swordholder'\n",
        "re.match(r'(^\\w.*)\\s\\u2013',text).group(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Cheng Xin (程心)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0imNRYMQRS3"
      },
      "source": [
        "urls = ['https://en.wikipedia.org/wiki/The_Three-Body_Problem_(novel)',\n",
        "        'https://en.wikipedia.org/wiki/The_Dark_Forest',\n",
        "        'https://en.wikipedia.org/wiki/Death%27s_End']\n",
        "characters = []\n",
        "for i, url in enumerate(urls):\n",
        "    page=requests.get(url)\n",
        "    soup=BeautifulSoup(page.content,'lxml')\n",
        "    lists = soup.find_all('li')\n",
        "    for li in lists:\n",
        "        element = re.findall(r'(^\\w.*)\\s[–-]', li.text)\n",
        "        # element = re.match(r'(^\\w.*)\\s–',text).group(1)\n",
        "        if(len(element) > 0):\n",
        "            characters.append([element[0], i+1])\n",
        "\n",
        "characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia9mukSdRNVx"
      },
      "source": [
        "characters_tab = pd.DataFrame(characters, columns=['Name', 'series'])\n",
        "characters_tab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxhmyW9HSMDN"
      },
      "source": [
        "characters_tab.groupby('Name').agg('count').sort_values('series', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5nkeARkU1Pf"
      },
      "source": [
        "# Exercise: using Openweathermap API to get current weather information in London\n",
        "\n",
        "Hint 1: Go to https://openweathermap.org/appid (https://openweathermap.org/appid) to register an account, get your API key (https://home.openweathermap.org/api_keys).\n",
        "\n",
        "Hint 2: To search the current weather for a particular city, try something like 'http://api.openweathermap.org/data/2.5/weather?q='+'city, country'+'&APPID='+api_key\n",
        "\n",
        "Hint 3: Import json file. After you apply the get method, use .json to extract the weather information\n",
        "\n",
        "You can get more weather report and forecast information here https://openweathermap.org/api (https://openweathermap.org/api)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtqFd79MWQwI",
        "outputId": "b5336291-b35a-40bd-e54f-a7c5cf2762a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/st445/lectures2020/Week5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/st445/lectures2020/Week5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T2ktKKkUK0q",
        "outputId": "fd67dac3-c0aa-4839-afa9-7d72b3fc9a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import json\n",
        "with open(\"APItemplate.json\", \"r\") as file:\n",
        "    API = json.load(file)\n",
        "api_key=API['OpenWeather']\n",
        "# api_key = ''\n",
        "query = 'q='+'London, uk'\n",
        "res=requests.get('http://api.openweathermap.org/data/2.5/weather?'+query+'&APPID='+api_key)\n",
        "print(res.json())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'coord': {'lon': -0.13, 'lat': 51.51}, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 285.7, 'feels_like': 280.19, 'temp_min': 284.82, 'temp_max': 287.04, 'pressure': 1002, 'humidity': 77}, 'visibility': 10000, 'wind': {'speed': 7.42, 'deg': 237}, 'clouds': {'all': 100}, 'dt': 1603894716, 'sys': {'type': 3, 'id': 2019646, 'country': 'GB', 'sunrise': 1603867648, 'sunset': 1603903253}, 'timezone': 0, 'id': 2643743, 'name': 'London', 'cod': 200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DphKy8Dtlh-o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}